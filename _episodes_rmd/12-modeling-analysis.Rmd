---
title: "Creating univariate regression models"
teaching: 45
exercises: 10
questions:
- "How can I make a graph of my regression?"
- "How can I look at residuals?"
- "How can I assess and remove outliers?"
- "How can I export publication-quality graphics?"
objectives:
- "Make a scatterplot"
- "`cor()`"
- "Learn how to run regressions with `lm()` and `glm()`"
- "Learn how to isolate parts of the matrix that `lm()` returns"
- "Learn how to run `t.test()` - get p-value, CI, etc."
- "Assess interactions between variables"
keypoints:
- "FIXME"
source: Rmd
---

<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

```{r, include=FALSE}
source("../bin/chunk-options.R")
knitr_fig_path("08-")
```

```{r, include=FALSE}
library(dplyr)

analysis_swan_df <- readRDS(file = "data_out/analysis_swan_df_08.rds")
colnames(analysis_swan_df)
```

# Regression models in R

Now that we have cleaned up the variables in our data frame, and are sufficiently satisfied that the variables of interest meet our assumptions for regression, we can proceed with building regression models.

Most of the commonly-used statistical tests and model-building functions are in R's built-in `stats` package, although there are certainly many other packages available with additional statistical functionality.

For simple linear regression, we can use the `lm()` function (`lm` stands for "linear model").  R also provides `glm()` for more generalized regression, which you can use not only for linear regression but also for logistic regression, Poisson regression, etc.  R's `stats()` package also has `anova()` and many other commonly used statistical computations.

We'll need to specify some parameters when we use `lm()`.  At a minumum, we need to specify:
* The data frame containing our data
* The formula for the model we'd like to fit.  In other words, which variable in our data frame is the "y" variable, and which combination of "x" variables are we including in our model.

There are other optional parameters available in `lm()` as well.

Our outcome variable of interest is `Glucose` which is a continuous variable, so linear regression is appropriate.  (If our outcome variable was a categorical variable, we'd be performing a logistic regression, for which we'd need to use `glm()`)

Before we build a full model, we will first assess the individual impact of each variable, independently, on the outcome, by conducting univariate regressions on each variable versus the outcome.

As we build these models, we'll keep an eye on the R-squared values and the F-test values.  We'll also decide on a cutoff for a *p*-value as a criteria for which variables to include in the multivariate model.  Let's use a *p*-value cutoff of 0.15.

For our first univariate model, we'll try fitting the following model:

$$
Glucose = \beta_0 + \beta_1bp\_category + \varepsilon
$$

Where $$\beta_0$$ is the y-intercept and $$\beta_1$$ is the slope, and $$\varepsilon$$ is the error term.

To compute this regression using `lm()`, we need to specify the `forumla` parameter and the `data` parameter.

The `formula` parameter expects an R formula object, which is expressed using a tilde (`~`) to relate a "y" variable to an expression containing "x" variables.  For example, formulas might look like:

`y ~ x`

`lung_cancer ~ smoker + age + gender + income`

Formulas can also include [interaction terms](https://en.wikipedia.org/wiki/Interaction_(statistics)):

`y ~ x1 + x2 + x1*x2`

Note that the names of the variables must be variables that are present in the data frame specified in the `data` parameter.

In our case, we have a relatively simple univariate model where `Glucose` is the "y" variable, and `bp_category` is our only "x" variable:

`Glucose ~ bp_category`

We'll store the resule of the regression in a variable we'll call `lm_bp`: 

```{r}
lm_bp <- lm(formula = Glucose ~ bp_category, data = analysis_swan_df)
```

Let's now take a look at the model that `lm()` computed:

```{r}
summary(lm_bp) # p<0.001 --> KEEP
```


```{r}
glm_age <- glm(Glucose ~ Age, data = analysis_swan_df)
summary(glm_age) # p<0.001 --> KEEP

glm_bmi <- glm(Glucose ~ BMI_cat, data = analysis_swan_df)
summary(glm_bmi) # p<0.001 --> KEEP

glm_hdl_ldl <- glm(Glucose ~ Chol_Ratio, data = analysis_swan_df)
summary(glm_hdl_ldl) # p<0.001 --> KEEP
# NOTE: since we are creating a ratio of HDL to LDL, we dont even need to evaluate LDL and HDL alone.

glm_race <- glm(Glucose ~ RACE, data = analysis_swan_df)
summary(glm_race) # p=0.207 is the smallest --> can keep but can also drop. let's see what the stepwise does. 

glm_exercise <- glm(Glucose ~ Exercise, data = analysis_swan_df)
summary(glm_exercise) # p<0.001 --> KEEP

glm_crp <- glm(Glucose ~ CRP, data = analysis_swan_df)
summary(glm_crp) # p<0.001 --> KEEP
```

<!-- #TODO Fix smoker glm and do everything below -->
<!-- ```{r} -->
<!-- glm_smoke <- glm(Glucose ~ Smoker, data = analysis_swan_df) -->
<!-- summary(glm_smoke) # p=0.0329 --> KEEP B/C LESS THAN 0.05 -->

<!-- ``` -->

<!-- # **** REMOVE BOTH OF THESE HDL AND LDL MODELS********* -->
<!-- ```{r} -->
<!-- glm_hdl <- glm(Glucose ~ HDL, data = analysis_swan_df) -->
<!-- summary(glm_hdl) # p<0.001 --> KEEP -->

<!-- glm_ldl <- glm(Glucose ~ LDL, data = analysis_swan_df) -->
<!-- summary(glm_ldl) # p=0.55--> DO NOT KEEP  -->

<!-- ``` -->

<!-- ***INTERACTION TERMS*** -->
<!-- ```{r} -->
<!-- analysis_swan_df$age_hdl_ldl <- analysis_swan_df$HDL_LDL * analysis_swan_df$AGE6 -->
<!-- ``` -->



<!-- *Full Models* -->
<!-- ```{r} -->
<!-- full_model <- glm(Glucose ~ BMI_cat + bp_category  + AGE6 + -->
<!--                     HDL_LDL + RACE + CRP + SMOKERE6 + EXERCIS6 + age_hdl_ldl, data = analysis_swan_df) -->
<!-- summary(full_model) -->
<!-- ``` -->

<!-- Plotting residuals -->
<!-- ```{r} -->
<!-- plot(resid(full_model)) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- rst <- rstandard(full_model) -->
<!-- qqnorm(rst, ylab = "Standardized Residuals",  -->
<!--        xlab = "Normal Scores") -->
<!-- qqline(rst) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- analysis_swan_df$cooksd <- cooks.distance(full_model) -->
<!-- cooksd_cutoff <- 4/nrow(analysis_swan_df) -->

<!-- plot(analysis_swan_df$cooksd) -->
<!-- abline(cooksd_cutoff, 0) -->
<!-- ``` -->

<!-- Dropping outliers -->
<!-- ```{r} -->
<!-- analysis_swan_df2 <- analysis_swan_df %>% filter(cooksd < cooksd_cutoff) %>% select(-cooksd) -->

<!-- full_model <- glm(Glucose ~ BMI_cat + bp_category  + AGE6 + -->
<!--                     HDL_LDL + RACE + CRP + SMOKERE6 + EXERCIS6 + age_hdl_ldl,  -->
<!--                     data = analysis_swan_df2) -->
<!-- summary(full_model) -->
<!-- ``` -->

<!-- Plotting residuals -->
<!-- ```{r} -->
<!-- plot(resid(full_model)) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- rst <- rstandard(full_model) -->
<!-- qqnorm(rst, ylab = "Standardized Residuals",  -->
<!--        xlab = "Normal Scores") -->
<!-- qqline(rst) -->
<!-- ``` -->


<!-- Cleaning data even further:  -->
<!-- remove: -->
<!-- triglycerides > 500 mg/dl -->
<!-- HDL > 100 mg/dl -->
<!-- Fasting glucose >=126 mg/dl -->
<!-- ```{r} -->
<!-- analysis_swan_df <- analysis_swan_df %>% filter(DBP>0 &  -->
<!--                                        HDL <=100 & -->
<!--                                         Glucose <126) -->
<!-- # dropping HDL >100 b/c that high level is actually bad for the heart - genetic issue -->
<!-- #fasting glycose of >=126 mg/dl is considered T2D -->
<!-- nrow(analysis_swan_df) -->


<!-- full_model <- glm(Glucose ~ BMI_cat + bp_category  + AGE6 + -->
<!--                     HDL_LDL + RACE + CRP + SMOKERE6 + EXERCIS6 + age_hdl_ldl, -->
<!--                     data = analysis_swan_df2) -->
<!-- summary(full_model) -->
<!-- ``` -->

<!-- Dropping outliers -->
<!-- ```{r} -->
<!-- analysis_swan_df2 <- analysis_swan_df %>% filter(cooksd < cooksd_cutoff) %>% select(-cooksd) -->

<!-- full_model <- glm(Glucose ~ BMI_cat + bp_category  + AGE6 + -->
<!--                     HDL_LDL + RACE + CRP + SMOKERE6 + EXERCIS6 + age_hdl_ldl,  -->
<!--                   data = analysis_swan_df2) -->
<!-- summary(full_model) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- rst <- rstandard(full_model) -->
<!-- qqnorm(rst, ylab = "Standardized Residuals",  -->
<!--        xlab = "Normal Scores") -->
<!-- qqline(rst) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- library(MASS) -->
<!-- # Stepwise regression model -->
<!-- step.model <- stepAIC(full_model, direction = "backward",  -->
<!--                       trace = TRUE ) -->
<!-- summary(step.model) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- rst <- rstandard(full_model) -->
<!-- qqnorm(rst, ylab = "Standardized Residuals",  -->
<!--        xlab = "Normal Scores") -->
<!-- qqline(rst) -->

<!-- library(car) -->

<!-- vif(glm(Glucose ~ BMI_cat + bp_category  + AGE6 +HDL_LDL + RACE + CRP +  -->
<!--           SMOKERE6 + EXERCIS6, data=analysis_swan_df2)) -->
<!-- # VIF has to be <=1 ??? -->

<!-- pairs(analysis_swan_df2 %>% dplyr::select(AGE6,  HDL_LDL)) -->
<!-- ``` -->


